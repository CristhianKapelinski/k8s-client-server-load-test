# Projeto: AvaliaÃ§Ã£o de Escalabilidade de AplicaÃ§Ãµes Cliente-Servidor TCP/IP em Kubernetes

![Capa do Projeto - Exemplo de logo ou Ã­cone de Kubernetes com clientes/servidores]

---

## ğŸš€ VisÃ£o Geral do Projeto

Este projeto visa avaliar a escalabilidade e o desempenho de aplicaÃ§Ãµes cliente-servidor baseadas em protocolo TCP/IP, utilizando as poderosas ferramentas de conteinerizaÃ§Ã£o Docker e orquestraÃ§Ã£o Kubernetes. O foco principal Ã© analisar como as implementaÃ§Ãµes de servidor e cliente em diferentes linguagens (Python e Go) se comportam sob variadas cargas de trabalho, identificando gargalos, comparando eficiÃªncias e fornecendo insights valiosos para o dimensionamento de sistemas distribuÃ­dos.

Diferente de abordagens tradicionais, o projeto utiliza um **cliente de teste persistente** dentro do cluster Kubernetes, que Ã© instruÃ­do dinamicamente a gerar diferentes nÃ­veis de carga, otimizando o overhead de criaÃ§Ã£o e deleÃ§Ã£o de pods a cada cenÃ¡rio de teste.

---

## âœ¨ Funcionalidades Principais

* **ImplementaÃ§Ãµes MÃºltiplas:** Servidores e clientes desenvolvidos em Python (com `asyncio`) e Go (com `goroutines`), permitindo uma comparaÃ§Ã£o de desempenho entre linguagens.
* **Protocolo TCP/IP Customizado:** ComunicaÃ§Ã£o cliente-servidor baseada em um protocolo de eco simples sobre TCP, fundamental para os testes.
* **Controle de Teste Otimizado:** O cliente de teste atua como um serviÃ§o persistente no Kubernetes, recebendo comandos via um protocolo TCP customizado para iniciar e gerenciar os testes de carga, eliminando o overhead de criaÃ§Ã£o de pods por cenÃ¡rio.
* **OrquestraÃ§Ã£o Kubernetes:** Gerenciamento automatizado de deployments de servidor (escalÃ¡vel) e cliente de teste (persistente), e serviÃ§os para comunicaÃ§Ã£o interna.
* **Testes de Carga Abrangentes:** CenÃ¡rios configurÃ¡veis que variam o nÃºmero de rÃ©plicas de servidor, a quantidade de clientes concorrentes (aumentando e diminuindo a carga) e o nÃºmero de mensagens por cliente.
* **Coleta e Processamento de Dados:** Logs detalhados sÃ£o coletados em formato JSON, processados por scripts Python e consolidados em arquivos CSV para anÃ¡lise estatÃ­stica.
* **GeraÃ§Ã£o AutomÃ¡tica de GrÃ¡ficos:** VisualizaÃ§Ãµes claras e informativas sÃ£o geradas para facilitar a interpretaÃ§Ã£o dos resultados de desempenho.
* **AutomaÃ§Ã£o Completa:** Um Ãºnico script Bash orquestra todo o ciclo de vida do projeto, desde a construÃ§Ã£o das imagens atÃ© a geraÃ§Ã£o dos resultados finais.

---

## ğŸ› ï¸ PrÃ©-requisitos de InstalaÃ§Ã£o

Para executar este projeto, vocÃª precisarÃ¡ ter os seguintes componentes instalados em seu sistema Ubuntu (ou similar):

* **Docker:** Para construÃ§Ã£o e gerenciamento de imagens de contÃªiner.
    * InstalaÃ§Ã£o: Siga a documentaÃ§Ã£o oficial do Docker para Ubuntu.
* **Minikube** (ou outro cluster Kubernetes local, como Kind ou Docker Desktop com Kubernetes ativado): Para simular um ambiente Kubernetes.
    * InstalaÃ§Ã£o Minikube: `curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 && sudo install minikube-linux-amd64 /usr/local/bin/minikube && rm minikube-linux-amd64`
* **kubectl:** A ferramenta de linha de comando para interaÃ§Ã£o com o cluster Kubernetes.
    * InstalaÃ§Ã£o kubectl: `sudo snap install kubectl --classic` ou `sudo apt-get update && sudo apt-get install -y kubectl`
* **Python 3.x:** Para compatibilidade com os cÃ³digos Python do cliente, servidor e scripts de automaÃ§Ã£o.
    * Verificar: `python3 --version`
* **`pip` (gerenciador de pacotes Python):**
    * Instalar: `sudo apt install python3-pip`
* **Bibliotecas Python:** `pandas`, `matplotlib`, `seaborn`.
    * Instalar: `pip install pandas matplotlib seaborn`
* **`jq`:** Ferramenta de linha de comando para processamento de JSON, utilizada pelos scripts.
    * Instalar: `sudo apt install jq`

---

## ğŸš€ Guia de ExecuÃ§Ã£o

Para rodar o projeto, siga estes passos. Ã‰ **fundamental que todos os arquivos de cÃ³digo-fonte estejam na raiz do diretÃ³rio do projeto** (juntamente com as pastas `logs/`).

1.  **Clonar o RepositÃ³rio:**
    ```bash
    git clone [https://github.com/CristhianKapelinski/k8s-client-server-load-test.git](https://github.com/CristhianKapelinski/k8s-client-server-load-test.git)
    cd k8s-client-server-load-test # Navegue atÃ© o diretÃ³rio raiz do projeto clonado
    ```

2.  **PreparaÃ§Ã£o do Ambiente:**
    * Certifique-se de que **todos os arquivos de cÃ³digo-fonte** (`.py`, `.go`, `.sh`, `.yaml`, `Dockerfile.*`) estejam **diretamente na raiz do projeto clonado**.


3.  **Configurar UsuÃ¡rio do Docker Hub:**
    Edite o arquivo `run_tests.sh` (que agora estÃ¡ na raiz) e defina a variÃ¡vel `DOCKER_USER` com seu nome de usuÃ¡rio do Docker Hub:
    ```bash
    # Dentro de run_tests.sh
    DOCKER_USER="seu_usuario_dockerhub"
    ```

4.  **Realizar Login no Docker Hub:**
    ```bash
    docker login
    ```

5.  **Iniciar o Cluster Kubernetes (Ex: Minikube):**
    ```bash
    minikube start --driver=docker
    ```
    Aguarde a completa inicializaÃ§Ã£o do Minikube. Verifique o status com `minikube status`.

6.  **Conceder PermissÃ£o de ExecuÃ§Ã£o ao Script Principal:**
    ```bash
    chmod +x run_tests.sh
    ```

7.  **Executar o Script de Testes:**
    Este comando executarÃ¡ todo o ciclo de vida do projeto: limpeza de recursos, construÃ§Ã£o e envio de imagens Docker (Python e Go), implantaÃ§Ã£o de servidores e clientes de teste no Kubernetes, execuÃ§Ã£o dos cenÃ¡rios de carga, coleta de logs, processamento de dados e geraÃ§Ã£o de grÃ¡ficos.

    ```bash
    ./run_tests.sh
    ```
    O script levarÃ¡ um tempo considerÃ¡vel para ser concluÃ­do, pois executarÃ¡ uma matriz de cenÃ¡rios abrangente.

---

## ğŸ“ Estrutura do RepositÃ³rio

Ao clonar este repositÃ³rio, vocÃª encontrarÃ¡ a seguinte estrutura:

```
. (raiz do projeto)
â”œâ”€â”€ analyze_results.py              # Script Python para anÃ¡lise estatÃ­stica dos resultados
â”œâ”€â”€ client.py                       # Cliente de teste persistente (Python)
â”œâ”€â”€ client.go                       # Cliente de teste persistente (Go)
â”œâ”€â”€ client-deployment.yaml          # Deployment do cliente de teste no Kubernetes
â”œâ”€â”€ client_control_proxy.py         # Script auxiliar para controlar o cliente via TCP
â”œâ”€â”€ Dockerfile.client               # Dockerfile do cliente Python
â”œâ”€â”€ Dockerfile.client.go            # Dockerfile do cliente Go
â”œâ”€â”€ Dockerfile.server               # Dockerfile do servidor Python
â”œâ”€â”€ Dockerfile.server.go            # Dockerfile do servidor Go
â”œâ”€â”€ generate_graphs.py              # Script Python para geraÃ§Ã£o dos grÃ¡ficos
â”œâ”€â”€ process_logs.py                 # Script Python para processar logs brutos JSON
â”œâ”€â”€ run_tests.sh                    # Script Bash principal de automaÃ§Ã£o do projeto
â”œâ”€â”€ server.py                       # Servidor TCP (Python)
â”œâ”€â”€ server.go                       # Servidor TCP (Go)
â”œâ”€â”€ server-deployment.yaml          # Deployment do servidor no Kubernetes
â”œâ”€â”€ test_build.sh                   # Script auxiliar para testar builds Docker
â”‚                                   # (nÃ£o faz parte do fluxo principal do run_tests.sh)
â”‚
â”œâ”€â”€ logs/                           # DiretÃ³rio para logs e resultados
â”‚   â”œâ”€â”€ graphs/                     # GrÃ¡ficos PNG gerados
â”‚   â”‚   â”œâ”€â”€ average_latency_vs_concurrent_clients_language_comparison.png
â”‚   â”‚   â”œâ”€â”€ average_latency_vs_server_replicas_language_comparison.png
â”‚   â”‚   â”œâ”€â”€ latency_vs_messages_language_scatter.png
â”‚   â”‚   â”œâ”€â”€ success_rate_vs_concurrent_clients_language_comparison.png
â”‚   â”‚   â””â”€â”€ total_messages_received_vs_concurrent_clients_language_comparison.png
â”‚   â”œâ”€â”€ raw_client_logs/            # Logs brutos (JSON) por linguagem (go/ e python/)
â”‚   â”œâ”€â”€ results_combined.csv        # CSV final com todos os resultados
â”‚   â”œâ”€â”€ results_go.csv              # CSV com resultados Go
â”‚   â”œâ”€â”€ results_python.csv          # CSV com resultados Python
â”‚   â””â”€â”€ (outros logs de pods e deployments)
â”‚
â””â”€â”€ README.md                       # Este arquivo
```

## ğŸ“Š AnÃ¡lise de Resultados e GrÃ¡ficos

A execuÃ§Ã£o do script `run_tests.sh` gera um conjunto abrangente de dados de desempenho, que sÃ£o processados e visualizados para facilitar a interpretaÃ§Ã£o. Os grÃ¡ficos em `logs/graphs/` oferecem uma representaÃ§Ã£o visual clara das tendÃªncias e comparaÃ§Ãµes.

### InterpretaÃ§Ã£o dos Resultados Chave:

Os testes abrangem uma vasta gama de cenÃ¡rios, variando o nÃºmero de rÃ©plicas de servidor, o volume de clientes concorrentes (de 1 a 1000, e vice-versa) e o nÃºmero de mensagens por cliente (1, 10, 100, 1000).

1.  **Robustez e Taxa de Sucesso:**
    * Ambas as implementaÃ§Ãµes (Python e Go) demonstraram uma **taxa de sucesso de 100%** em todos os cenÃ¡rios testados. Isso Ã© um indicativo excepcional de robustez na entrega e processamento das mensagens, sem perdas ou falhas de conexÃ£o, mesmo sob as condiÃ§Ãµes de estresse mais elevadas. Isso valida a confiabilidade tanto das implementaÃ§Ãµes quanto da infraestrutura Kubernetes.

2.  **LatÃªncia MÃ©dia: Go vs. Python:**
    * **Go:** Apresentou uma latÃªncia mÃ©dia significativamente menor e mais consistente. Em cenÃ¡rios de baixa carga, a latÃªncia mÃ©dia foi extremamente baixa (entre **0.14 ms e 0.34 ms**). Mesmo sob cargas muito elevadas, a latÃªncia do Go permaneceu notavelmente baixa, atingindo no mÃ¡ximo **12.12 ms**. O aumento no nÃºmero de rÃ©plicas de servidores contribuiu para uma diminuiÃ§Ã£o ainda maior da latÃªncia em Go, demonstrando sua excelente escalabilidade horizontal.
    * **Python:** Enquanto as latÃªncias iniciais em Python sÃ£o comparÃ¡veis Ã s de Go em cargas muito baixas, o desempenho se degrada mais visivelmente Ã  medida que a carga aumenta. Em cenÃ¡rios de alta concorrÃªncia, a latÃªncia do Python pode atingir valores como **33.85 ms**, e picos extremos chegaram a **192.43 ms**.
    * **ConclusÃ£o:** A implementaÃ§Ã£o em Go Ã©, em mÃ©dia, mais rÃ¡pida e mais consistente (com menor desvio padrÃ£o) que a implementaÃ§Ã£o em Python, especialmente sob cargas elevadas. A natureza compilada de Go e seu modelo de concorrÃªncia com goroutines oferecem um overhead menor e latÃªncias mais previsÃ­veis para esta workload intensiva.

3.  **Capacidade de Processamento:**
    * Ambas as linguagens e a arquitetura Kubernetes demonstraram ser capazes de processar um volume massivo de mensagens. O sistema foi testado para lidar com cenÃ¡rios de atÃ© **1.000.000 de mensagens recebidas** em uma Ãºnica combinaÃ§Ã£o de cenÃ¡rio, com sucesso.

### VisualizaÃ§Ã£o dos Resultados:

Os grÃ¡ficos abaixo ilustram as principais tendÃªncias de desempenho e a comparaÃ§Ã£o entre as implementaÃ§Ãµes Python e Go.

#### LatÃªncia MÃ©dia vs. Clientes Concorrentes

Este grÃ¡fico mostra como a latÃªncia mÃ©dia por mensagem se comporta Ã  medida que o nÃºmero de clientes concorrentes aumenta, com linhas separadas para diferentes configuraÃ§Ãµes de servidor e linguagens. Observa-se claramente a vantagem de latÃªncia do Go sobre o Python, especialmente em cargas mais altas.

![LatÃªncia MÃ©dia por Mensagem vs. Clientes Concorrentes (ComparaÃ§Ã£o Python vs Go)](logs/graphs/average_latency_vs_concurrent_clients_language_comparison.png)

#### Taxa de Sucesso vs. Clientes Concorrentes

Este grÃ¡fico demonstra a robustez do sistema, exibindo a taxa de sucesso das mensagens em relaÃ§Ã£o ao nÃºmero de clientes concorrentes. A constÃ¢ncia em 100% para ambas as linguagens em todos os cenÃ¡rios Ã© um ponto forte do projeto.

![Taxa de Sucesso do CenÃ¡rio vs. Clientes Concorrentes (ComparaÃ§Ã£o Python vs Go)](logs/graphs/success_rate_vs_concurrent_clients_language_comparison.png)

#### Total de Mensagens Recebidas vs. Clientes Concorrentes

Este grÃ¡fico visualiza o volume total de mensagens que o sistema conseguiu processar com sucesso para cada configuraÃ§Ã£o de cliente concorrente. Ele reforÃ§a a capacidade do sistema de lidar com grandes volumes de dados.

![Total de Mensagens Recebidas vs. Clientes Concorrentes (ComparaÃ§Ã£o Python vs Go)](logs/graphs/total_messages_received_vs_concurrent_clients_language_comparison.png)

#### LatÃªncia MÃ©dia vs. RÃ©plicas do Servidor

Este grÃ¡fico de barras compara a latÃªncia mÃ©dia em relaÃ§Ã£o ao nÃºmero de rÃ©plicas do servidor, para ambas as linguagens. Ele destaca como a escalabilidade horizontal (adicionar mais servidores) impacta a reduÃ§Ã£o da latÃªncia e a capacidade de resposta do sistema.

![LatÃªncia MÃ©dia por Mensagem vs. NÃºmero de RÃ©plicas do Servidor (ComparaÃ§Ã£o Python vs Go)](logs/graphs/average_latency_vs_server_replicas_language_comparison.png)

#### LatÃªncia MÃ©dia vs. Mensagens Recebidas (Scatter Plot)

Este grÃ¡fico de dispersÃ£o oferece uma visÃ£o mais detalhada da relaÃ§Ã£o entre o volume total de mensagens processadas e a latÃªncia mÃ©dia, discriminando por linguagem e indicando a intensidade da concorrÃªncia (tamanho dos pontos).

![LatÃªncia MÃ©dia vs. Mensagens Recebidas (Scatter Plot por CenÃ¡rio e Linguagem)](logs/graphs/latency_vs_messages_language_scatter.png)

---

## ğŸ’¡ PrÃ³ximos Passos e OtimizaÃ§Ãµes Futuras

* **AnÃ¡lise de Throughput:** Embora a latÃªncia e a taxa de sucesso sejam cruciais, o throughput (mensagens por segundo) Ã© outra mÃ©trica vital. A implementaÃ§Ã£o da coleta de dados de throughput (tempo total de execuÃ§Ã£o de cada cenÃ¡rio) pode fornecer uma visÃ£o mais completa.
* **Monitoramento AvanÃ§ado:** Integrar ferramentas de monitoramento de cluster Kubernetes (como Prometheus e Grafana) para coletar mÃ©tricas de CPU, memÃ³ria e rede dos pods durante os testes pode fornecer insights mais profundos sobre o uso de recursos e gargalos.
* **Testes de ResiliÃªncia:** Explorar cenÃ¡rios de falha (ex: derrubar pods de servidor durante um teste) para avaliar a resiliÃªncia do sistema e a eficÃ¡cia das retentativas do cliente.

---

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues, enviar pull requests ou sugerir melhorias.

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

**Autor:** Seu Nome / Nome da Equipe
**Data:** 15 de Junho de 2025